{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gqr-Wl_0C7t"
      },
      "source": [
        "# Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8J8Arat0C7x",
        "outputId": "5cce4d96-614a-4303-adeb-f452deb861fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading train-images-idx3-ubyte.gz...\n",
            "Downloaded train-images-idx3-ubyte.gz!\n",
            "Downloading t10k-images-idx3-ubyte.gz...\n",
            "Downloaded t10k-images-idx3-ubyte.gz!\n",
            "Downloading train-labels-idx1-ubyte.gz...\n",
            "Downloaded train-labels-idx1-ubyte.gz!\n",
            "Downloading t10k-labels-idx1-ubyte.gz...\n",
            "Downloaded t10k-labels-idx1-ubyte.gz!\n",
            "Downloaded all files!\n",
            "Saving mnist.pkl...\n",
            "Saved mnist.pkl!\n",
            "Deleting temporary file train-images-idx3-ubyte.gz...\n",
            "Deleted temporary file train-images-idx3-ubyte.gz!\n",
            "Deleting temporary file t10k-images-idx3-ubyte.gz...\n",
            "Deleted temporary file t10k-images-idx3-ubyte.gz!\n",
            "Deleting temporary file train-labels-idx1-ubyte.gz...\n",
            "Deleted temporary file train-labels-idx1-ubyte.gz!\n",
            "Deleting temporary file t10k-labels-idx1-ubyte.gz...\n",
            "Deleted temporary file t10k-labels-idx1-ubyte.gz!\n",
            "Deleted all temporary files!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import gzip, pickle, os\n",
        "from urllib import request\n",
        "\n",
        "base_uri = \"http://yann.lecun.com/exdb/mnist/\"\n",
        "\n",
        "filename = [\n",
        "    [\"training_images\",\"train-images-idx3-ubyte.gz\"],\n",
        "    [\"test_images\",\"t10k-images-idx3-ubyte.gz\"],\n",
        "    [\"training_labels\",\"train-labels-idx1-ubyte.gz\"],\n",
        "    [\"test_labels\",\"t10k-labels-idx1-ubyte.gz\"]\n",
        "]\n",
        "\n",
        "\n",
        "def download_mnist():\n",
        "    for name in filename:\n",
        "        print(f'Downloading {name[1]}...')\n",
        "        request.urlretrieve(f'{base_uri}{name[1]}', name[1])\n",
        "        print(f'Downloaded {name[1]}!')\n",
        "    print(f'Downloaded all files!')\n",
        "\n",
        "\n",
        "def save_mnist():\n",
        "    print(f'Saving mnist.pkl...')\n",
        "    mnist = {}\n",
        "    for name in filename[:2]:\n",
        "        with gzip.open(name[1], 'rb') as f:\n",
        "            mnist[name[0]] = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1,28*28)\n",
        "    for name in filename[-2:]:\n",
        "        with gzip.open(name[1], 'rb') as f:\n",
        "            mnist[name[0]] = np.frombuffer(f.read(), np.uint8, offset=8)\n",
        "    with open(\"mnist.pkl\", 'wb') as f:\n",
        "        pickle.dump(mnist,f)\n",
        "    print(\"Saved mnist.pkl!\")\n",
        "\n",
        "\n",
        "def delete_temp_files():\n",
        "    for name in filename:\n",
        "        print(f'Deleting temporary file {name[1]}...')\n",
        "        os.remove(name[1])\n",
        "        print(f'Deleted temporary file {name[1]}!')\n",
        "    print(f'Deleted all temporary files!')\n",
        "\n",
        "\n",
        "download_mnist()\n",
        "save_mnist()\n",
        "delete_temp_files()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4SWicMv0C70"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QB8QlcVO0C71",
        "outputId": "6d431a4a-41b1-467b-c77a-cf6dcabee41b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training images shape: (60000, 784)\n",
            "Training labels shape: (60000,)\n",
            "Testing images shape: (10000, 784)\n",
            "Testing labels shape: (10000,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from urllib import request\n",
        "import gzip\n",
        "import pickle\n",
        "\n",
        "\n",
        "def load():\n",
        "    with open(\"mnist.pkl\",'rb') as f:\n",
        "        mnist = pickle.load(f)\n",
        "\n",
        "        training_images, training_labels, testing_images, testing_labels = mnist[\"training_images\"], mnist[\"training_labels\"], mnist[\"test_images\"], mnist[\"test_labels\"]\n",
        "        # Normalize the images\n",
        "        training_images.astype('float32')\n",
        "        testing_images.astype('float32')\n",
        "        training_images = training_images / 255\n",
        "        testing_images = testing_images / 255\n",
        "        return training_images, training_labels, testing_images, testing_labels\n",
        "\n",
        "\n",
        "training_images,training_labels,testing_images,testing_labels=load()\n",
        "print(f'Training images shape: {training_images.shape}')\n",
        "print(f'Training labels shape: {training_labels.shape}')\n",
        "print(f'Testing images shape: {testing_images.shape}')\n",
        "print(f'Testing labels shape: {testing_labels.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqncnTBb0C72"
      },
      "source": [
        "# Display Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "IZ2FrBIX0C72",
        "outputId": "ea29fcc4-bb03-4fd1-ae0b-87e42b3f373a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: 0\n",
            "Example training image: 59370\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_image(image):\n",
        "\n",
        "    # Swapped out what was in the hand out code with this since it was\n",
        "    # less cluttered.\n",
        "    plt.imshow(image.reshape(28,28))\n",
        "    plt.show()\n",
        "\n",
        "random_index = np.random.randint(0,training_images.shape[0])\n",
        "\n",
        "print(f'Label: {np.argmax(training_labels[random_index])}')\n",
        "print(f'Example training image: {random_index}')\n",
        "\n",
        "show_image(training_images[random_index])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FelJYT4r0C73"
      },
      "source": [
        "# The Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "rmTbf-SS0C74"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "class NeuralNetwork():\n",
        "  def __init__ (self, layer_sizes, learning_rate, momentum, epochs, batch_size):\n",
        "    self.layer_sizes = layer_sizes\n",
        "    self.learning_rate = learning_rate\n",
        "    self.momentum = momentum\n",
        "    self.epochs = epochs\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "\n",
        "  def train(self, training_images, training_labels):\n",
        "    print('Training the neural network...')\n",
        "\n",
        "    self.W1 = 0.1*np.random.randn(self.layer_sizes[0], self.layer_sizes[1])\n",
        "    self.B1 = np.zeros((1, self.layer_sizes[1]))\n",
        "\n",
        "    self.W2 = 0.1*np.random.randn(self.layer_sizes[1], self.layer_sizes[2])\n",
        "    self.B2 = np.zeros((1, self.layer_sizes[2]))\n",
        "\n",
        "    self.W3 = 0.1*np.random.randn(self.layer_sizes[2], self.layer_sizes[3])\n",
        "    self.B3 = np.zeros((1, self.layer_sizes[3]))\n",
        "\n",
        "    for epoch in range(self.epochs):\n",
        "      start_time = time.time()\n",
        "\n",
        "      for batch_start in range(0, training_images.shape[0], self.batch_size):\n",
        "        batch_images = training_images[batch_start:batch_start+self.batch_size]\n",
        "        batch_labels = training_labels[batch_start:batch_start+self.batch_size]\n",
        "\n",
        "        # Forward pass\n",
        "        hidden_layer1, hidden_layer2, probs = self._forward(batch_images)\n",
        "\n",
        "        # Backward pass\n",
        "        self._backpass(hidden_layer1=hidden_layer1, hidden_layer2=hidden_layer2, output_layer=probs, training_images=batch_images, training_labels=batch_labels)\n",
        "\n",
        "      end_time = time.time() - start_time\n",
        "      print (f'Epoch: {epoch + 1}, Time: {end_time.__round__(2)}s, Accuracy: {self.check_accuracy(training_images, training_labels).__round__(2) * 100}%')\n",
        "\n",
        "    print('Training complete!')\n",
        "\n",
        "\n",
        "  def _forward (self, training_images):\n",
        "    \"\"\"Performs a forward pass through the network.\n",
        "\n",
        "    Args:\n",
        "        training_images (numpy.ndarray): The training images.\n",
        "\n",
        "    Returns:\n",
        "        hidden_layer1 (numpy.ndarray): The output of the first hidden layer.\n",
        "        hidden_layer2 (numpy.ndarray): The output of the second hidden layer.\n",
        "        output_layer (numpy.ndarray): The output of the output layer.\n",
        "    \"\"\"\n",
        "\n",
        "    hidden_layer1=self._relu(np.dot(training_images,self.W1)+self.B1)\n",
        "    hidden_layer2=self._relu(np.dot(hidden_layer1,self.W2)+self.B2)\n",
        "    scores=np.dot(hidden_layer2,self.W3)+self.B3\n",
        "\n",
        "    output = self._softmax(scores)\n",
        "    return hidden_layer1, hidden_layer2, output\n",
        "\n",
        "\n",
        "  def _backpass (self, hidden_layer1, hidden_layer2, output_layer, training_images, training_labels):\n",
        "    \"\"\"Performs a backpass on the network.\n",
        "\n",
        "    Args:\n",
        "        hidden_layer1 (numpy.ndarray): The first hidden layer of the network.\n",
        "        hidden_layer2 (numpy.ndarray): The second hidden layer of the network.\n",
        "        hidden_layer2 (numpy.ndarray): The output layer of the network.\n",
        "        training_images (numpy.ndarray): The training images.\n",
        "        training_labels (numpy.ndarray): The training labels.\n",
        "    \"\"\"\n",
        "\n",
        "    dscores = output_layer\n",
        "    dscores[range(len(training_images)), training_labels] -= 1\n",
        "    dscores /= len(training_images)\n",
        "\n",
        "    dw3=np.dot(hidden_layer2.T,dscores)\n",
        "    db3=np.sum(dscores, axis=0,keepdims=True)\n",
        "\n",
        "    dhidden2=np.dot(dscores, self.W3.T)\n",
        "    dhidden2[hidden_layer2 <=0]=0\n",
        "\n",
        "    dw2=np.dot(hidden_layer1.T, dhidden2)\n",
        "    db2=np.sum(dhidden2, axis=0,keepdims=True)\n",
        "\n",
        "    dhidden1=np.dot(dhidden2, self.W2.T)\n",
        "    dhidden1[hidden_layer1 <=0]=0\n",
        "\n",
        "    dw1=np.dot(training_images.T, dhidden1)\n",
        "    db1=np.sum(dhidden1,axis=0,keepdims=True)\n",
        "\n",
        "    # Update delta weights.\n",
        "    dw3 += self.momentum*self.W3\n",
        "    dw2 += self.momentum*self.W2\n",
        "    dw1 += self.momentum*self.W1\n",
        "\n",
        "    # Updates the weights.\n",
        "    self.W1 += -self.learning_rate * dw1\n",
        "    self.W2 += -self.learning_rate * dw2\n",
        "    self.W3 += -self.learning_rate * dw3\n",
        "\n",
        "    # Updates biases.\n",
        "    self.B1 += -self.learning_rate * db1\n",
        "    self.B2 += -self.learning_rate * db2\n",
        "    self.B3 += -self.learning_rate * db3\n",
        "\n",
        "  def predict(self, image):\n",
        "    \"\"\"Predicts the label of an image.\n",
        "\n",
        "    Args:\n",
        "        image (numpy.ndarray): The image to predict the label of.\n",
        "\n",
        "    Returns:\n",
        "        int: The predicted label.\n",
        "    \"\"\"\n",
        "\n",
        "    _, _, output = self._forward(image)\n",
        "    return np.argmax(output)\n",
        "\n",
        "\n",
        "  def check_accuracy (self, validation_images, validation_labels):\n",
        "    \"\"\"Checks the accuracy of the network on the validation set.\n",
        "\n",
        "    Args:\n",
        "        validation_images (numpy.ndarray): The validation images.\n",
        "        validation_labels (numpy.ndarray): The validation labels.\n",
        "\n",
        "    Returns:\n",
        "        accuracy (float): The accuracy of the network on the validation set.\n",
        "    \"\"\"\n",
        "\n",
        "    _, _, output = self._forward(validation_images)\n",
        "\n",
        "    count = 0\n",
        "    for i in range(len(validation_images)):\n",
        "      if np.argmax(output[i]) == validation_labels[i]:\n",
        "        count += 1\n",
        "    return count / len(validation_images)\n",
        "\n",
        "\n",
        "  def _relu (self, x, derivative=False):\n",
        "    \"\"\"Computes the rectified linear unit.\n",
        "    \n",
        "    Args:\n",
        "        x (numpy.ndarray): The input data.\n",
        "        derivative (bool): Whether to compute the derivative of the relu or not.\n",
        "        \n",
        "    Returns:\n",
        "        numpy.ndarray: The relu of the input data.\n",
        "    \"\"\"    \n",
        "\n",
        "    if derivative:\n",
        "      return np.where(x > 0, 1, 0)\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "\n",
        "  def _softmax(self, x, derivative=False):\n",
        "    \"\"\"Computes the softmax activation function.\n",
        "    \n",
        "    Args:\n",
        "        x (numpy.ndarray): The input data.\n",
        "        derivative (bool): Whether to compute the derivative of the softmax or not.\n",
        "        \n",
        "    Returns:\n",
        "        numpy.ndarray: The softmax of the input data.\n",
        "    \"\"\"\n",
        "\n",
        "    if derivative:\n",
        "      return x * (1 - x)\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ncSa59O0C75"
      },
      "source": [
        "# Network Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "hXBwEvH00C76",
        "outputId": "fff4d442-89d0-4e96-d019-6222157fe032"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training the neural network...\n",
            "Epoch: 1, Time: 2.31s, Accuracy: 91.0%\n",
            "Epoch: 2, Time: 2.22s, Accuracy: 94.0%\n",
            "Epoch: 3, Time: 2.69s, Accuracy: 95.0%\n",
            "Epoch: 4, Time: 2.43s, Accuracy: 96.0%\n",
            "Epoch: 5, Time: 2.88s, Accuracy: 97.0%\n",
            "Epoch: 6, Time: 2.62s, Accuracy: 97.0%\n",
            "Epoch: 7, Time: 3.68s, Accuracy: 97.0%\n",
            "Epoch: 8, Time: 2.8s, Accuracy: 97.0%\n",
            "Epoch: 9, Time: 2.41s, Accuracy: 98.0%\n",
            "Epoch: 10, Time: 2.43s, Accuracy: 98.0%\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(0)\n",
        "nn = NeuralNetwork([784, 200, 50, 10], 0.1, 1e-3, 10, 128)\n",
        "nn.train(training_images, training_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Network Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image number: 21285\n",
            "\n",
            "Predicted: 3\n",
            "Actual: 3\n"
          ]
        }
      ],
      "source": [
        "image_index = np.random.randint(0, len(training_images))\n",
        "\n",
        "predicted = nn.predict(training_images[image_index])\n",
        "actual = training_labels[image_index]\n",
        "\n",
        "print(f'Image number: {image_index}')\n",
        "print()\n",
        "print('Predicted:', predicted)\n",
        "print('Actual:', actual)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "neural-network-numpy.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "51e9f5af3309fe15d5305c3bba8f0577071aa0e6e25f79a412a09d63415d6187"
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
